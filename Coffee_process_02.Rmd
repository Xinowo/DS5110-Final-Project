---
title: "Coffee_review_processed_02"
author: "Henry Guo"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, tidy.opts = list(width.cutoff = 300))
```

```{r}
library("easypackages")                                             
libraries("tidyverse","ggthemes",
          "ggplot2", "scales", "dplyr", "readr", "stringr","tidytext",
          "tidyr", "DBI", "RSQLite")
coffee <- read_csv("~/Desktop/coffee_review_processed_01.csv")
```

Finding most popular Coffee Origins
```{r}
coffee <- coffee %>%
  mutate(coffee_origin_lower = tolower(`Coffee Origin`)) %>% 
  mutate(roast_level = tolower(`Roast Level`))

top_words <- coffee %>%
  unnest_tokens(word, coffee_origin_lower) %>%
  count(word, sort = TRUE) %>%
  slice_head(n = 100)
#top_words
```

Here are the countries / regions where it appeared more than 100 times:ethiopia, columbia, kenya, guatemala, yirgacheffe (ethiopia), indonesia, costa rica, sumatra (indonesia), brazil, panama, sidamo (ethiopia), oromia(ethiopia), guji(ethiopia), salvador, boquete(panama), nyeri (kenya), huila (columbia), kona (hawaii), rwanda, cauca (columb), sidama (ethiopia), honduras, huehuetenango (guatemala), nicaragua, peru, hawaii, hawai'i, mexico, tarrazu (costa rica), gerais (brazil), guinea, papua (guinea), aceh (indonesia), antigua

Below are coffee_origin categorized. Please adjust if you see fit.
```{r}
coffee <- coffee %>%
  mutate(coffee_origin = str_replace_all(coffee_origin_lower, "[^[:alnum:]]", "")) %>% 
  mutate(coffee_origin_adj = case_when(
    str_detect(coffee_origin, "colomb") ~ "colombia",
    str_detect(coffee_origin, "brazil") ~ "brazil",
    str_detect(coffee_origin, "guatem") ~ "guatemala",
    str_detect(coffee_origin, "kenya") ~ "kenya",
    str_detect(coffee_origin, "ethiopia") ~ "ethiopia",
    str_detect(coffee_origin, "yirgacheffe") ~ "ethiopia",
    str_detect(coffee_origin, "indo") ~ "indonesia",
    str_detect(coffee_origin, "costa") ~ "costa rica",
    str_detect(coffee_origin, "rica") ~ "costa rica",
    str_detect(coffee_origin, "sumatra") ~ "indonesia",
    str_detect(coffee_origin, "sidamo") ~ "ethiopia",
    str_detect(coffee_origin, "oromia") ~ "ethiopia",
    str_detect(coffee_origin, "guji") ~ "ethiopia",
    str_detect(coffee_origin, "salvador") ~ "salvador",
    str_detect(coffee_origin, "boquete") ~ "panama",
    str_detect(coffee_origin, "panama") ~ "panama",
    str_detect(coffee_origin, "nyeri") ~ "kenya",
    str_detect(coffee_origin, "huila") ~ "colombia",
    str_detect(coffee_origin, "kona") ~ "hawaii",
    str_detect(coffee_origin, "rwan") ~ "rwanda",
    str_detect(coffee_origin, "cauca") ~ "colombia",
    str_detect(coffee_origin, "hondu") ~ "honduras",
    str_detect(coffee_origin, "huehuetenango") ~ "guatemala",
    str_detect(coffee_origin, "nicaragua") ~ "nicaragua",
    str_detect(coffee_origin, "peru") ~ "peru",
    str_detect(coffee_origin, "hawa") ~ "hawaii",
    str_detect(coffee_origin, "mexico") ~ "mexico",
    str_detect(coffee_origin, "tarrazu") ~ "costa rica",
    str_detect(coffee_origin, "gerais") ~ "brazil",
    str_detect(coffee_origin, "guinea") ~ "australia",
    str_detect(coffee_origin, "australia") ~ "australia",
    str_detect(coffee_origin, "papua") ~ "australia",
    str_detect(coffee_origin, "aceh") ~ "indonesia",
    str_detect(coffee_origin, "antigua") ~ "antigua",
    str_detect(coffee_origin, "cong") ~ "congo",
    str_detect(coffee_origin, "puert") ~ "peurto rico",
    str_detect(coffee_origin, "yemen") ~ "yemen",
    str_detect(coffee_origin, "taiwan") ~ "taiwan",
    str_detect(coffee_origin, "china") ~ "china",
    str_detect(coffee_origin, "india") ~ "india",
    str_detect(coffee_origin, "philippine") ~ "philippines",
    str_detect(coffee_origin, "jamaica") ~ "jamaica",
    str_detect(coffee_origin, "bolivia") ~ "bolivia",
    str_detect(coffee_origin, "haiti") ~ "haiti",
    str_detect(coffee_origin, "kayanza") ~ "burundi",
    str_detect(coffee_origin, "burundi") ~ "burundi",
    str_detect(coffee_origin, "thai") ~ "thailand",
    str_detect(coffee_origin, "viet") ~ "vietnam",
    str_detect(coffee_origin, "cali") ~ "united states",
    str_detect(coffee_origin, "tanzania") ~ "tanzania",
    str_detect(coffee_origin, "ecuador") ~ "ecuador",
    str_detect(coffee_origin, "uganda") ~ "uganda",
    str_detect(coffee_origin, "zimbab") ~ "zimbabwe",
    str_detect(coffee_origin, "zambia") ~ "zambia",
    str_detect(coffee_origin, "dominic") ~ "dominican republic",
    str_detect(coffee_origin, "disclose") ~ "NA",
    str_detect(coffee_origin, "NA") ~ "NA",
    #TRUE ~ coffee_origin
    TRUE ~ "others"
  ))
```

Roast Level Adjustment
```{r}
coffee <- coffee %>%
  mutate(roast_lv_adj = case_when(
    roast_level == "very dark" ~ 6,
    roast_level == "dark" ~ 5,
    roast_level == "medium-dark" ~ 4,
    roast_level == "medium" ~ 3,
    roast_level == "medium-light" ~ 2,
    roast_level == "light" ~ 1,
    TRUE ~ NA_real_ 
  ))
```
Coffee name with 100%
```{r}
coffee <- coffee %>%
  mutate(coffee_name_hundredpercent =str_detect(`Coffee Name`, "100"))
```

Review data from character to date-time.
```{r}
coffee <- coffee %>%
  mutate(review_date_adj = as.Date(paste("01", `Review Date`), format = "%d %B %Y"))
```

```{r}
coffee <- coffee %>% #for more convenient typing
  rename(A=`Blind Assessment`, B=`Notes`, C=`Who Should Drink It`, D=`Bottom Line`)

coffee <- coffee %>% 
  select(-`all_text`, -`Agtron`,-`Est. Price`,-`Roast Level`, -`roast_level`,-`coffee_origin_lower`,-`coffee_origin`,-`Est. Price`,-`Review Date`)
write_csv(coffee, "~/Desktop/coffee_ultimato.csv")
```

Word Frequency Raw Count
```{r}
top_words_by_column <- coffee %>%
  pivot_longer(cols = c(A, B, C, D), names_to = "column", values_to = "text") %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word") %>%
  count(column, word, sort = TRUE) %>%
  group_by(column) %>%
  slice_max(order_by = n, n = 20) %>%
  ungroup()

ggplot(top_words_by_column, aes(x = reorder(word, n), y = n)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ column, scales = "free_y") +
  labs(x = "Word", y = "Frequency", title = "Top 30 Words per Column") +
  coord_flip()+
  theme(axis.text.y = element_text(angle = 325, size = 5.7))
```
Word Frequency TF-IDF
```{r}
tfidf_data <- coffee %>%
  pivot_longer(cols = c(A, B, C, D),
               names_to = "document",
               values_to = "text") %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!(document == "B" & str_detect(word, "\\d"))) %>%
  count(document, word, sort = TRUE) %>%
  bind_tf_idf(word, document, n)

tfidf_top <- tfidf_data %>%
  group_by(document) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  arrange(document, -tf_idf)

ggplot(tfidf_top, aes(x = reorder_within(word, tf_idf, document), y = tf_idf, fill = document)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ document, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = "Word", y = "TF-IDF", title = "Top TF-IDF Words per Column") +
  theme(axis.text.y = element_text(angle = 335, size = 6.5))
```

```{r}
coffee <- coffee %>%
  mutate(review_id = row_number())

# 2. Pivot the comment columns into long format.
#    Retain review_id and Rating (assuming the Rating column is named exactly "Rating").
coffee_long <- coffee %>%
  pivot_longer(cols = c(A, B, C, D),
               names_to = "document",
               values_to = "text")

# 3. Tokenize the text and remove stop words:
tokens <- coffee_long %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

# 4. Count words in each review & document (each review's comment):
token_counts <- tokens %>%
  count(review_id, document, word, sort = TRUE)

# 5. Compute TF-IDF.
#    Here we treat each review (review_id) as a document. If you prefer to compute it separately for each comment column,
#    you could use a composite key (e.g., paste(review_id, document, sep = "_")). For now, we assume review-level TF-IDF:
tfidf_data <- token_counts %>%
  bind_tf_idf(word, review_id, n)

# 6. Summarize text features per review and per comment type.
#    For example, calculate average TF-IDF (you could also compute total TF-IDF, etc.).
review_features <- tfidf_data %>%
  group_by(review_id, document) %>%
  summarise(avg_tf_idf = mean(tf_idf), .groups = "drop")

# 7. Join these text features back with the original ratings.
coffee_features <- coffee %>%
  select(review_id, Rating) %>%
  left_join(review_features, by = "review_id")

# 8. Visualize the relationship between average TF-IDF and Rating for each comment column.
ggplot(coffee_features, aes(x = avg_tf_idf, y = Rating)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  facet_wrap(~ document) +
  labs(x = "Average TF-IDF", y = "Rating", title = "Rating vs Average TF-IDF by Comment Column") +
  theme_minimal()
```
TF-IDF per review per comment type creates a numeric value representing the importance of words in the comments. We see that in A,B,C, reviewers tend to give lower ratings when using more distinctive language in the comment, and vice versa.

```{r}
 # 1. Create a unique review id if you don't have one already.
coffee <- coffee %>%
  mutate(review_id = row_number())

# 2. Pivot comment columns (A, B, C, D) into long format.
coffee_long <- coffee %>%
  pivot_longer(cols = c(A, B, C, D),
               names_to = "document",
               values_to = "text")

# 3. Tokenize and remove stop words:
tokens <- coffee_long %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

# (Optional) Remove tokens containing numbers from specific documents if needed.
tokens <- tokens %>%
  filter(!(document == "B" & str_detect(word, "\\d")))

# 4. Count words for each review & comment
token_counts <- tokens %>%
  count(review_id, document, word, sort = TRUE)

# 5. Compute TF-IDF
tfidf_data <- token_counts %>%
  bind_tf_idf(word, review_id, n)

# 6. Aggregate the TF-IDF per review and per comment.
#    Here, we take the average TF-IDF, though you might experiment with sum, median, etc.
review_features <- tfidf_data %>%
  group_by(review_id, document) %>%
  summarise(avg_tf_idf = mean(tf_idf), .groups = "drop")

# 7. Join the aggregated numeric feature(s) back to your original data (including Rating).
#    (Make sure "Rating" is in your original data and that review_id is common.)
coffee_features <- coffee %>%
  select(review_id, Rating) %>%
  left_join(review_features, by = "review_id")

# 8. Perform the correlation analysis.
#    Here, we calculate the correlation for each comment column (document).
cor_results <- coffee_features %>%
  group_by(document) %>%
  summarise(correlation = cor(avg_tf_idf, Rating, use = "complete.obs"))

print(cor_results)
```
Reviewers tend to give harsher ratings when using distinctive words in the order of A > B > C >D

```{r}

```