{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to parsing the text data into dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the total number of available reviews on sitemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 15 URLs.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Get all review URLs from the sitemap\n",
    "sitemap_url = \"https://www.coffeereview.com/sitemap_index.xml\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Fetch and parse the sitemap XML\n",
    "response = requests.get(sitemap_url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    all_urls = [loc.text for loc in soup.find_all(\"loc\")]\n",
    "    print(f\"✅ Found {len(all_urls)} URLs.\")\n",
    "else:\n",
    "    print(f\"❌ Failed to fetch sitemap. Status code: {response.status_code}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.coffeereview.com/review-sitemap.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap2.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap3.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap4.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap5.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap6.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap7.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap8.xml',\n",
       " 'https://www.coffeereview.com/review-sitemap9.xml']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sitemaps = [url for url in all_urls if \"review-sitemap\" in url]\n",
    "review_sitemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 1001 review URLs in sitemap https://www.coffeereview.com/review-sitemap.xml.\n",
      "✅ Found 1000 review URLs in sitemap https://www.coffeereview.com/review-sitemap2.xml.\n",
      "✅ Found 1040 review URLs in sitemap https://www.coffeereview.com/review-sitemap3.xml.\n",
      "✅ Found 1057 review URLs in sitemap https://www.coffeereview.com/review-sitemap4.xml.\n",
      "✅ Found 1056 review URLs in sitemap https://www.coffeereview.com/review-sitemap5.xml.\n",
      "✅ Found 1067 review URLs in sitemap https://www.coffeereview.com/review-sitemap6.xml.\n",
      "✅ Found 1058 review URLs in sitemap https://www.coffeereview.com/review-sitemap7.xml.\n",
      "✅ Found 1049 review URLs in sitemap https://www.coffeereview.com/review-sitemap8.xml.\n",
      "✅ Found 422 review URLs in sitemap https://www.coffeereview.com/review-sitemap9.xml.\n",
      "Found 8750 review URLs in total.\n"
     ]
    }
   ],
   "source": [
    "all_review_urls = []\n",
    "\n",
    "for this_sitemap in review_sitemaps:\n",
    "    # Fetch and parse the sitemap XML\n",
    "    response = requests.get(this_sitemap, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"xml\")\n",
    "        review_urls = [loc.text for loc in soup.find_all(\"loc\")]\n",
    "        print(f\"✅ Found {len(review_urls)} review URLs in sitemap {this_sitemap}.\")\n",
    "        all_review_urls = all_review_urls + review_urls\n",
    "    else:\n",
    "        print(f\"❌ Failed to fetch sitemap. Status code: {response.status_code}\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8749 review URLs in total.\n",
      "Found 8748 unique review URLs in total.\n"
     ]
    }
   ],
   "source": [
    "if \"https://www.coffeereview.com/review/\" in all_review_urls:\n",
    "    all_review_urls.remove(\"https://www.coffeereview.com/review/\")\n",
    "\n",
    "print(f\"Found {len(all_review_urls)} review URLs in total.\")\n",
    "print(f\"Found {len(set(all_review_urls))} unique review URLs in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found duplicated review urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.coffeereview.com/wp-content/uploads/2014/11/29_375x375.jpg\n"
     ]
    }
   ],
   "source": [
    "def first_duplicate(lst):\n",
    "    seen = set()\n",
    "    for item in lst:\n",
    "        if item in seen:\n",
    "            return item\n",
    "        seen.add(item)\n",
    "    return None\n",
    "\n",
    "print(first_duplicate(all_review_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the scrapped reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https___www_coffeereview_com_review_100-colombian_.txt',\n",
       " 'https___www_coffeereview_com_review_moka-java_.txt',\n",
       " 'https___www_coffeereview_com_review_java_.txt',\n",
       " 'https___www_coffeereview_com_review_sumatra-gayo-mountain_.txt',\n",
       " 'https___www_coffeereview_com_review_folgers-french-roast_.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_from_sitemap = [re.sub(r\"[^\\w\\-]\", \"_\", url) + \".txt\" for url in all_review_urls]\n",
    "reviews_from_sitemap[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8747\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./coffee_reviews_text/\"\n",
    "scrapped_texts = os.listdir(folder_path)\n",
    "print(len(scrapped_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https___www_coffeereview_com_wp-content_uploads_2019_02_6_375x375_jpg.txt'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check differences between reviews_from_sitemap and scrapped_texts\n",
    "set_1 = set(reviews_from_sitemap)\n",
    "set_2 = set(scrapped_texts)\n",
    "\n",
    "set_1 ^ set_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference will not have influence because we will not use wp-content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 8387 unique reviews for analysis.\n"
     ]
    }
   ],
   "source": [
    "# Remove 360 wp-content files\n",
    "scrapped_reviews = [filename for filename in scrapped_texts if \"wp-content\" not in filename]\n",
    "print(f\"We will use {len(scrapped_reviews)} unique reviews for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number should align with the number of reviews (until 03/03/2025) on the website https://www.coffeereview.com/review/:\n",
    "$20 \\times 414 + 4 = 8284$. However, it looks like we scrapped more reviews ($8387 > 8284$) than those shown on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all text files and save as csv with raw texts which need to be parsed further\n",
    "Done by Xin on 03/03/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regex patterns\n",
    "url_pattern = re.compile(r'URL:\\s*(https?://\\S+)')\n",
    "all_text_pattern = re.compile(r'“行銷攻略” 促銷活動\\s*(.*?)\\s*Explore Similar Coffees', re.DOTALL)\n",
    "\n",
    "def extract_info(text):\n",
    "    \"\"\"Extract URL and relevant text from the review file\"\"\"\n",
    "    url = url_pattern.search(text)\n",
    "    all_text = all_text_pattern.search(text)\n",
    "    \n",
    "    return {\n",
    "        \"URL\": url.group(1) if url else None,\n",
    "        \"all_text\": all_text.group(1).strip() if all_text else None,\n",
    "    }\n",
    "\n",
    "data = []\n",
    "for file_name in scrapped_reviews:\n",
    "    with open(os.path.join(folder_path, file_name), \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        extracted_info = extract_info(text)\n",
    "        data.append(extracted_info)\n",
    "\n",
    "# Store data in DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.coffeereview.com/review/__trashed-5/\n",
      "94\n",
      "JBC Coffee Roasters\n",
      "Kagunyu Kenya\n",
      "Roaster Location:\n",
      "Madison, Wisconsin\n",
      "Coffee Origin:\n",
      "Nyeri County, Kenya\n",
      "Roast Level:\n",
      "Medium-Light\n",
      "Agtron:\n",
      "60/78\n",
      "Est. Price:\n",
      "$22.00/12 ounces\n",
      "Review Date:\n",
      "February 2024\n",
      "Aroma:\n",
      "9\n",
      "Acidity/Structure:\n",
      "9\n",
      "Body:\n",
      "9\n",
      "Flavor:\n",
      "9\n",
      "Aftertaste:\n",
      "8\n",
      "Blind Assessment\n",
      "Complex, multi-layered, deep-toned. Red currant, cocoa nib, tangerine, fresh-cut oak, marjoram in aroma and cup. Bright, juicy structure with phosphoric (cola-like) acidity; crisp, syrupy mouthfeel. Resonant finish centered around notes of red currant and cocoa nib.\n",
      "Notes\n",
      "Produced by smallholding farmers, from trees of the SL28 and SL34 varieties of Arabica, and processed by the traditional washed method (fruit skin and pulp removed before drying) at the Kagunyu Washing Station. JBC Coffee Roasters’ vision is simple: “Let the coffee lead the way” through sourcing and roasting the best and most unique coffees available and rewarding the farmers who grow those coffees with substantial premiums. Visit\n",
      "www.jbccoffeeroasters.com\n",
      "or call 608-256-5282 for more information\n",
      "Bottom Line\n",
      "A classic Kenya cup with its bright currant, cocoa nib and citrus impulses, and its sparkling acidity — and recognizably so, both aromatically and in the flavor profile.\n"
     ]
    }
   ],
   "source": [
    "# check_index = 8386\n",
    "# print(df[\"URL\"][check_index])\n",
    "# print(df[\"all_text\"][check_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"coffee_review_raw_texts.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Text Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
